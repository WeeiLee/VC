{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pediatric-audit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "#from deepface.commons import functions\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-vulnerability",
   "metadata": {},
   "source": [
    "# Definición de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSVMPredictions(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "    print(\"SVM Normalization...\")\n",
    "    scaler = MinMaxScaler()\n",
    "    train_X = scaler.fit_transform(X_train)\n",
    "    test_X = scaler.transform(X_test)\n",
    "\n",
    "    print(\"SVM training...\")\n",
    "    t0 = time()\n",
    "    parameters = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],}\n",
    "    # Grid serach across parameter range\n",
    "    clf = GridSearchCV(\n",
    "        SVC(kernel='rbf', class_weight='balanced'), parameters, cv=5\n",
    "    )\n",
    "    clf = clf.fit(train_X, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "\n",
    "\n",
    "    print(\"Predicting\")\n",
    "    t0 = time()\n",
    "    y_pred = clf.predict(test_X)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    return y_pred, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "favorite-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_embs(X, batch_size=2): #No usada desde 2024 en el código\n",
    "    norm_images = prewhiten(X)\n",
    "    pd = []\n",
    "    for start in range(0, len(norm_images), batch_size):\n",
    "        pd.append(model.predict_on_batch(norm_images[start:start+batch_size]))     #https://github.com/serengil/deepface/issues/819           \n",
    "    return l2_normalize(np.concatenate(pd))\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "\n",
    "def LoadDataset(folder, ext):\n",
    "    # Contador de número de clases del conjunto\n",
    "    nclasses = 0\n",
    "    # Contador de muestras por clase\n",
    "    nperclass = []\n",
    "    # Etiqueta de cada clase (nombre de la subcarpeta)\n",
    "    classlabels = []\n",
    "    # Inicializa estructuras de datos y sus correpondientes etiquetas\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    preprocessing = 0\n",
    "\n",
    "    # Asume que en la ruta indicada hay una subcarpeta por clase\n",
    "    for class_name in os.listdir(folder):\n",
    "        # Cada subcarpeta implica una clase más\n",
    "        nclasses += 1\n",
    "        # Inicialmente esta clase no tiene muestras\n",
    "        nsamples = 1    \n",
    "\n",
    "        # Compone la ruta\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        for file_name in os.listdir(class_folder):\n",
    "            # Asume imágenes en formato ext\n",
    "            if file_name.endswith(ext):\n",
    "                # Lee la imagen\n",
    "                image = cv2.imread (os.path.join(class_folder, file_name))  \n",
    "\n",
    "                # Obtiene embeddings\n",
    "                img1 = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                # Hasta 2023 usaba\n",
    "                # Get embeddings after preprocessing\n",
    "                #if preprocessing == 1:\n",
    "                #    img_embedding = calc_embs(np.array([img1]))\n",
    "                #else:\n",
    "                #    img_embedding = model.predict(img1[None,...])\n",
    "\n",
    "                #X.append(img_embedding[0])\n",
    "                \n",
    "                #Desde 2024\n",
    "                embedding_objs = DeepFace.represent(img_path = img1,model_name  = \"Facenet\", enforce_detection = False)   \n",
    "                img_embedding = embedding_objs[0][\"embedding\"]             \n",
    "\n",
    "                X.append(img_embedding)\n",
    "\n",
    "                # Añade etiqueta numérica de la muestra\n",
    "                Y.append(nclasses-1)\n",
    "\n",
    "                #Incrementa el número de muestras\n",
    "                nsamples += 1\n",
    "\n",
    "        nperclass.append(nsamples)\n",
    "        classlabels.append(class_name)\n",
    "\n",
    "    #Convierte a numpy array X e Y\n",
    "    X = np.array(X,dtype='float32')\n",
    "    Y = np.array(Y,dtype='float64')\n",
    "\n",
    "    # Muestra datos del conjunto leído\n",
    "    # Depuración\n",
    "    print(\"Features\")\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    # Obtiene número de muestras y características\n",
    "    n_samples , n_features = X.shape\n",
    "    # Obtiene nombres de las clases\n",
    "    class_names = np.array(classlabels)\n",
    "    n_classes = class_names.shape[0]\n",
    "    \n",
    "    return X, Y, n_samples, n_features, n_classes, classlabels, nperclass, class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-tissue",
   "metadata": {},
   "source": [
    "# Carga conjuntos de datos\n",
    "\n",
    "Se proporciona la carpeta, a través de la variable folder, donde cada subcarpeta se corresponde con una clase.\n",
    "Cada clase contiene muestras en forma de imágenes jpg, todas del mismo tamaño. Obtiene embeddings Facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos disponibles ['VGG-Face', 'Facenet', 'OpenFace', 'DeepFace', 'DeepID', 'Dlib']\n",
    "model = DeepFace.build_model(\"Facenet\")\n",
    "dim = model.input_shape\n",
    "\n",
    "#MODIFICAR INDICANDO RUTA EN TU EQUIPO TRAS DESCAGAR DATOS DEL CAMPUS. EVITAR TILDES\n",
    "folder = \"Races\"\n",
    "\n",
    "print('Loading dataset')\n",
    "X, Y, nsamples, class_name, nperclass, classlabels, width, height = LoadDataset(folder,'.jpg')\n",
    "\n",
    "#Convierte a numpy array X e Y\n",
    "X = np.array(X,dtype='float32')\n",
    "Y = np.array(Y,dtype='float64')\n",
    "\n",
    "# Obtiene número de muestras y características\n",
    "n_samples , n_features = X.shape\n",
    "# Obtiene nombres de las clases\n",
    "class_names = np.array(classlabels)\n",
    "n_classes = class_names.shape[0]\n",
    "\n",
    "print(\"Dataset info:\")\n",
    "print(\"# samples: %d\" % n_samples)\n",
    "print(\"# features: %d\" % n_features)\n",
    "print(\"# classes: %d\" % n_classes)\n",
    "print(\"classes %s\" % classlabels)\n",
    "print(\"samples per class %s\" % str(nperclass)[1:-1] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd33ba7",
   "metadata": {},
   "source": [
    "# Diseña conjunto experimental k-fold\n",
    "\n",
    "Divide los datos k veces en conjunto de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebca6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold\n",
    "# Define el número de subconjuntos a considerar\n",
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=4, shuffle=True)\n",
    "#Distribución de muestras por fold\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(\"Fold %d\" % fold)\n",
    "    print(\"# samples in training set %d\" % train_index.shape[0])\n",
    "    print(\"# samples in test set %d\" % test_index.shape[0])\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-sensitivity",
   "metadata": {},
   "source": [
    "# Lanza experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-jenny",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kfold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Recorre folds\u001b[39;00m\n\u001b[32m      7\u001b[39m fold = \u001b[32m1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fold <= \u001b[43mkfold\u001b[49m:\n\u001b[32m      9\u001b[39m     accs, precs, recs = [], [], []\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m skf.split(X, Y):\n\u001b[32m     11\u001b[39m         \u001b[38;5;66;03m#print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'kfold' is not defined"
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "precs_facenet_svm, recs_facenet_svm = [], []\n",
    "precs_facenet_knn, recs_facenet_knn = [], []\n",
    "\n",
    "\n",
    "# Recorre folds\n",
    "fold = 1\n",
    "while fold <= kfold:\n",
    "    accs, precs, recs = [], [], []\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        print(\"***\\nFold %d\" % fold)\n",
    "        #División de muestras de entreno y test\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        #Etiquetas de las muestras\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "\n",
    "        #Facenet+SVM\n",
    "        y_pred, y_test = GetSVMPredictions(X_train, X_test,y_train, y_test)\n",
    "        print(\"\\nFacenet+SVM Metrics\")\n",
    "        precs_facenet_svm.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recs_facenet_svm.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "        print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))        \n",
    "    \n",
    "\n",
    "    fold += 1\n",
    "\n",
    "print(\"Facenet+KNN Mean Precision:  %0.3f, Mean Recall:  %0.3f\" % ( np.mean(precs_facenet_knn) , np.mean(recs_facenet_knn) ))\n",
    "print(\"Facenet+SVM Mean Precision:  %0.3f, Mean Recall:  %0.3f\" % ( np.mean(precs_facenet_svm) , np.mean(recs_facenet_svm) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a7c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from deepface import DeepFace\n",
    "\n",
    "# DNN\n",
    "dnn_model = \"deploy.prototxt.txt\"\n",
    "dnn_weights = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "net = cv2.dnn.readNetFromCaffe(dnn_model, dnn_weights)\n",
    "\n",
    "# Classifier + scaler\n",
    "clf = joblib.load(\"svm_final_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "class_names = [\"Asian\", \"Caucasian\", \"African\"]\n",
    "\n",
    "# Load crowns (with alpha)\n",
    "crowns = {\n",
    "    \"Asian\": cv2.imread(\"c1.png\", cv2.IMREAD_UNCHANGED),\n",
    "    \"Caucasian\": cv2.imread(\"c2.png\", cv2.IMREAD_UNCHANGED),\n",
    "    \"African\": cv2.imread(\"c3.png\", cv2.IMREAD_UNCHANGED),\n",
    "}\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "def overlay_png(frame, png, x, y, w):\n",
    "    \"\"\"Superpone PNG con canal alfa sobre frame en coordenada x,y\"\"\"\n",
    "    if png is None:\n",
    "        return frame\n",
    "\n",
    "    # resize keeping ratio\n",
    "    scale = w / png.shape[1]\n",
    "    new_w = int(png.shape[1] * scale)\n",
    "    new_h = int(png.shape[0] * scale)\n",
    "    png_resized = cv2.resize(png, (new_w, new_h))\n",
    "\n",
    "    # Coordinates\n",
    "    y1 = max(0, y - new_h)\n",
    "    y2 = y1 + new_h\n",
    "    x1 = x\n",
    "    x2 = x1 + new_w\n",
    "\n",
    "    if x1 < 0 or y1 < 0 or x2 > frame.shape[1] or y2 > frame.shape[0]:\n",
    "        return frame  # avoid errors if goes out of frame\n",
    "\n",
    "    # Split channels\n",
    "    b, g, r, a = cv2.split(png_resized)\n",
    "    overlay_color = cv2.merge((b, g, r))\n",
    "    mask = a / 255.0\n",
    "\n",
    "    # Apply alpha blending\n",
    "    frame_region = frame[y1:y2, x1:x2]\n",
    "    frame[y1:y2, x1:x2] = (overlay_color * mask[..., None] +\n",
    "                           frame_region * (1 - mask[..., None])).astype(np.uint8)\n",
    "    return frame\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # Face detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),\n",
    "                                 [104.0, 177.0, 123.0], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            x, y, x2, y2 = box.astype(int)\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            face = frame[y:y2, x:x2]\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Deepface embedding\n",
    "            embedding_objs = DeepFace.represent(face, model_name=\"Facenet\",\n",
    "                                                enforce_detection=False)\n",
    "            embedding = np.array(embedding_objs[0][\"embedding\"]).reshape(1, -1)\n",
    "            embedding = scaler.transform(embedding)\n",
    "\n",
    "            # Predict class\n",
    "            idx = int(clf.predict(embedding)[0])\n",
    "            class_name = class_names[idx]\n",
    "\n",
    "            # Draw text\n",
    "            cv2.putText(frame, class_name, (x, y2 + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Select crown PNG\n",
    "            crown_png = crowns[class_name]\n",
    "\n",
    "            # Apply crown on top of head\n",
    "            face_width = x2 - x\n",
    "            frame = overlay_png(frame, crown_png, x, y, face_width)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
