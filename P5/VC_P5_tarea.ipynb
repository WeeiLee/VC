{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336a2a46",
   "metadata": {},
   "source": [
    "## Tarea\n",
    "Tras mostrar opciones para la detección y extracción de información de caras humanas con deepface, la tarea a entregar consiste en proponer dos escenarios de aplicación y desarrollar dos prototipos de temática libre que provoquen reacciones a partir de la información extraída del rostro. Uno de los prototipos deberá incluir el uso de algún modelo entrenado por ustedes para la extracción de información biometríca, similar al ejemplo del género planteado durante la práctica pero con diferente aplicación (emociones, raza, edad...). El otro es de temática completamente libre.\n",
    "\n",
    "Los detectores proporcionan información del rostro, y de sus elementos faciales. Ideas inmediatas pueden ser filtros, aunque no hay limitaciones en este sentido. La entrega debe venir acompañada de un gif animado o vídeo de un máximo de 30 segundos con momentos seleccionados de las propuestas. Las propuestas se utilizarán para una posterior votación y elección de las mejores entre el grupo. El podio del curso pasado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67f2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\anaconda3\\envs\\VC_P5_1\\lib\\site-packages\\mtcnn\\mtcnn.py:34: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "c:\\Users\\antho\\anaconda3\\envs\\VC_P5_1\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "# My face detectors interface\n",
    "import FaceDetectors\n",
    "import numpy as np\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f2543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point(object):\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "def mouse_events(event, x, y, flags, params):\n",
    "    global points_list, accessory_images, accessory_names, image_id, points_images\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        closer_point = get_closer_point(points_list, x, y)\n",
    "        if closer_point is not None:\n",
    "            points_images[closer_point] = accessory_images[accessory_names[image_id]]\n",
    "    if event == cv2.EVENT_RBUTTONUP:\n",
    "        closer_point = get_closer_point(points_list, x, y)\n",
    "        if closer_point is not None and closer_point in points_images:\n",
    "            del points_images[closer_point]\n",
    "\n",
    "def get_closer_point(points, x, y):\n",
    "    min_dist = 10\n",
    "    min_p = None\n",
    "    for i in range(len(points)):\n",
    "        p = points[i]\n",
    "        dist = np.sqrt((p.x - x)**2 + (p.y - y)**2)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_p = i\n",
    "    return min_p\n",
    "\n",
    "def draw_png(img, frame, point):\n",
    "    x_start = point.x - img.shape[1] // 2\n",
    "    y_start = point.y - img.shape[0] // 2\n",
    "    x_end = x_start + img.shape[1]\n",
    "    y_end = y_start + img.shape[0]\n",
    "    \n",
    "    # Recorta si se sale del frame\n",
    "    H, W = frame.shape[:2]\n",
    "    if x_start < 0 or y_start < 0 or x_end > W or y_end > H:\n",
    "        return  # evita errores, mejor recortar, te puedo dar versión avanzada si quieres\n",
    "\n",
    "    # Separar canales\n",
    "    acc_rgb   = img[:, :, :3]\n",
    "    acc_alpha = img[:, :, 3] / 255.0\n",
    "\n",
    "    roi = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    # Hacer blending por cada canal\n",
    "    for c in range(3):\n",
    "        roi[:, :, c] = roi[:, :, c] * (1 - acc_alpha) + acc_rgb[:, :, c] * acc_alpha\n",
    "\n",
    "    frame[y_start:y_end, x_start:x_end] = roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2fbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter(frame):\n",
    "    b, g, r = cv2.split(frame)\n",
    "    r = np.roll(r, 4, axis=1)\n",
    "    b = np.roll(b, -4, axis=1)\n",
    "    frame = cv2.merge((b, g, r))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n"
     ]
    }
   ],
   "source": [
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "# Face detectors interface\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "# Fonts\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "    # Face detection and eye model setup\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "debug = 0\n",
    "\n",
    "image_id = 0\n",
    "points_list = [Point(0,0) for i in range(68)]\n",
    "points_images = dict()\n",
    "accessory_images = dict()\n",
    "show_debug = True\n",
    "\n",
    "tears_list_right = list()\n",
    "tear_creation_time_right = list()\n",
    "tears_list_left = list()\n",
    "tear_creation_time_left = list()\n",
    "\n",
    "tear_image = cv2.imread(\"./Polyphemustears.webp\", cv2.IMREAD_UNCHANGED)\n",
    "tear_image = cv2.resize(tear_image, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "accessory_names = []\n",
    "for (dirpath, dirnames, filenames) in walk(\"./isaac_images\"):\n",
    "    accessory_names.extend(filenames)\n",
    "    break\n",
    "\n",
    "accesory_size = 32\n",
    "accesory_icon_size = 64\n",
    "use_filter = False\n",
    "\n",
    "for name in accessory_names:\n",
    "    img = cv2.imread(\"./isaac_images/\" + name, cv2.IMREAD_UNCHANGED)\n",
    "    accessory_images[name] = img\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "# Create window\n",
    "ret, frame = cap.read()\n",
    "cv2.imshow(\"Cam\", frame)\n",
    "\n",
    "# Set mouse callback\n",
    "cv2.setMouseCallback(\"Cam\", mouse_events)\n",
    "\n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # For HS normalization\n",
    "        B, G, R = cv2.split(frame)\n",
    "\n",
    "        # Search face with a specific setup for face and eye detection\n",
    "        values = FDet.SingleFaceEyesDetection(frame, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "\n",
    "        for i in range(len(tears_list_right)):\n",
    "            if tears_list_right[i] is None:\n",
    "                continue\n",
    "            tear = tears_list_right[i]\n",
    "            creation_time = tear_creation_time_right[i]\n",
    "            # Simple gravity effect\n",
    "            elapsed = time.time() - creation_time\n",
    "            tear.y = tear.y * 1.0 + int(100 * elapsed * elapsed)\n",
    "            tear.y = int(tear.y)\n",
    "            if tear.y > frame.shape[0] + 16:\n",
    "                index = tears_list_right.index(tear)\n",
    "                tears_list_right[index] = None\n",
    "                tear_creation_time_right[index] = None\n",
    "            draw_png(tear_image, frame, tear)\n",
    "\n",
    "        for i in range(len(tears_list_left)):\n",
    "            if tears_list_left[i] is None:\n",
    "                continue\n",
    "            tear = tears_list_left[i]\n",
    "            creation_time = tear_creation_time_left[i]\n",
    "            # Simple gravity effect\n",
    "            elapsed = time.time() - creation_time\n",
    "            tear.y = tear.y * 1.0 + int(100 * elapsed * elapsed)\n",
    "            tear.y = int(tear.y)\n",
    "            if tear.y > frame.shape[0] + 16:\n",
    "                index = tears_list_left.index(tear)\n",
    "                tears_list_left[index] = None\n",
    "                tear_creation_time_left[index] = None\n",
    "            draw_png(tear_image, frame, tear)\n",
    "\n",
    "        if use_filter:\n",
    "            frame = filter(frame)\n",
    "        \n",
    "        if values is not None:\n",
    "            face, eyes, shape = values\n",
    "\n",
    "            #draws face container\n",
    "            [x, y , w, h] = face\n",
    "            if x > -1:\n",
    "                if show_debug:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                # draws eyes and mask if available\n",
    "                [lex, ley, rex, rey] = eyes\n",
    "                if lex > -1:\n",
    "                    # Show detected facial elements\n",
    "                    if imodoF > 0:\n",
    "                        points_list = []\n",
    "                        for (x, y) in shape:\n",
    "                            if show_debug:\n",
    "                                cv2.circle(frame, (x, y), 2, (255, 255, 255), -1)\n",
    "                            points_list.append(Point(x, y))\n",
    "\n",
    "                    if show_debug:\n",
    "                        cv2.circle(frame, ((int)(lex), (int)(ley)), 4, (0, 0, 255), -1)\n",
    "                        cv2.circle(frame, ((int)(rex), (int)(rey)), 4, (0, 255, 0), -1)\n",
    "                    \n",
    "                    # Show accesory selected\n",
    "                    accessory_name = accessory_names[image_id]\n",
    "                    accessory_img = accessory_images[accessory_name]\n",
    "\n",
    "\n",
    "                    image_to_show = cv2.resize(accessory_img, (accesory_icon_size, accesory_icon_size), interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    accesory_x = frame.shape[1]*6//7 - image_to_show.shape[1]//2\n",
    "                    accesory_y = frame.shape[0]*2//4 - image_to_show.shape[0]//2\n",
    "                    \n",
    "                    frame[accesory_y:accesory_y+image_to_show.shape[0], accesory_x:accesory_x+image_to_show.shape[1]] = image_to_show[:,:,0:3]\n",
    "\n",
    "            # draw images in points\n",
    "            for name, img in points_images.items():\n",
    "                point = points_list[int(name)]\n",
    "                referencia = 180 \n",
    "                ratio = w / referencia\n",
    "                scaled_size = int(accesory_size * ratio)\n",
    "\n",
    "                # límites para evitar tamaños inválidos\n",
    "                scaled_size = max(8, min(scaled_size, 512))\n",
    "\n",
    "                img_resized = cv2.resize(img, (scaled_size, scaled_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                draw_png(img_resized, frame, point)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "        # Show resulting image\n",
    "        cv2.putText(frame, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        if imodoF == 1 or imodoF == 2:\n",
    "            cv2.putText(frame, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('Cam', frame)\n",
    "        \n",
    "        # Esc to finish\n",
    "        tec = cv2.waitKey(40)\n",
    "        if tec & tec == 27:  # Esc\n",
    "            break\n",
    "        # Face detector change\n",
    "        \n",
    "        elif tec & 0xFF == ord('d'):\n",
    "            image_id = image_id + 1\n",
    "            if image_id >= len(accessory_names):\n",
    "                image_id = 0\n",
    "        #Eye detector change\n",
    "        elif tec & 0xFF == ord('a'):\n",
    "            image_id = image_id - 1\n",
    "            if image_id < 0:\n",
    "                image_id = len(accessory_names) - 1\n",
    "        elif tec & 0xFF == ord(' '):\n",
    "            show_debug = not show_debug\n",
    "        elif tec & 0xFF == ord('s'):\n",
    "            use_filter = not use_filter\n",
    "        elif tec & 0xFF == ord('e'):\n",
    "            tears_list_right.insert(0, Point(points_list[46].x, points_list[46].y + 10))\n",
    "            tear_creation_time_right.insert(0, time.time())\n",
    "        elif tec & 0xFF == ord('q'):\n",
    "            tears_list_left.insert(0, Point(points_list[41].x, points_list[41].y + 10))\n",
    "            tear_creation_time_left.insert(0, time.time())\n",
    "        # if tec != -1:\n",
    "            # print(tec)\n",
    "\n",
    "# Close windoews and release camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
